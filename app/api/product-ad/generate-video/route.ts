/**
 * ì œí’ˆ ê´‘ê³  ì˜ìƒ ìƒì„± API
 *
 * POST: ì„ íƒëœ ì²« ì”¬ ì´ë¯¸ì§€ë¡œ Seedance 1.5ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ìƒì„ ìƒì„±í•©ë‹ˆë‹¤.
 */

import { NextRequest, NextResponse } from 'next/server'
import { createClient } from '@/lib/supabase/server'
import { prisma } from '@/lib/db'
import { GoogleGenAI, GenerateContentConfig, ThinkingLevel, Type } from '@google/genai'
import {
  submitSeedanceToQueue,
  submitWan26ToQueue,
  type SeedanceAspectRatio,
  type SeedanceDuration,
  type Wan26Duration,
  type Wan26Resolution,
} from '@/lib/kie/client'
import { PRODUCT_AD_VIDEO_CREDIT_COST } from '@/lib/credits'

// Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
const genAI = new GoogleGenAI({
  apiKey: process.env.GOOGLE_AI_API_KEY!,
})

const MODEL_NAME = 'gemini-3-flash-preview'

interface ScenarioElements {
  background: string
  mood: string
  cameraAngle: string
  productPlacement: string
  lighting: string
  colorTone: string
}

type VideoModel = 'seedance' | 'kling2.6' | 'wan2.6'

interface GenerateVideoRequest {
  draftId?: string
  startFrameUrl: string
  productName: string
  scenarioElements: ScenarioElements
  aspectRatio: '16:9' | '9:16' | '1:1'
  duration: number  // 4, 8, 12
  multiShot?: boolean  // ë©€í‹°ìƒ· ëª¨ë“œ
  videoCount?: number  // ìƒì„±í•  ì˜ìƒ ê°œìˆ˜ (1-3)
  videoModel?: VideoModel  // ì˜ìƒ ìƒì„± ëª¨ë¸ (ê¸°ë³¸: seedance)
}

// ë¹„ìœ¨ ë§¤í•‘ (Seedanceìš©)
function mapAspectRatioForSeedance(ratio: '16:9' | '9:16' | '1:1'): SeedanceAspectRatio {
  const mapping: Record<string, SeedanceAspectRatio> = {
    '16:9': '16:9',
    '9:16': '9:16',
    '1:1': '1:1',
  }
  return mapping[ratio] || '9:16'
}

// Duration ë§¤í•‘ (SeedanceëŠ” 4, 8, 12ì´ˆ ì§€ì›)
function mapDurationForSeedance(duration: number): SeedanceDuration {
  if (duration <= 5) return '4'
  if (duration <= 10) return '8'
  return '12'
}

// Duration ë§¤í•‘ (Wan 2.6ì€ 5, 10, 15ì´ˆ ì§€ì›)
function mapDurationForWan26(duration: number): Wan26Duration {
  if (duration <= 7) return '5'
  if (duration <= 12) return '10'
  return '15'
}

export async function POST(request: NextRequest) {
  try {
    const supabase = await createClient()
    const { data: { user }, error: authError } = await supabase.auth.getUser()

    if (authError || !user) {
      return NextResponse.json(
        { error: 'Unauthorized' },
        { status: 401 }
      )
    }

    const body: GenerateVideoRequest = await request.json()
    const {
      draftId,
      startFrameUrl,
      productName,
      scenarioElements,
      aspectRatio,
      duration,
      multiShot = false,
      videoCount = 1,
      videoModel = 'seedance',
    } = body

    if (!startFrameUrl || !productName || !scenarioElements) {
      return NextResponse.json(
        { error: 'Missing required fields' },
        { status: 400 }
      )
    }

    // ìƒì„±í•  ì˜ìƒ ê°œìˆ˜ ì œí•œ (ìµœëŒ€ 3ê°œ)
    const count = Math.min(Math.max(videoCount, 1), 3)

    // í¬ë ˆë”§ ê³„ì‚°
    const getVideoCreditCost = (): number => {
      if (videoModel === 'wan2.6') {
        const durationKey = duration <= 7 ? 5 : duration <= 12 ? 10 : 15
        return PRODUCT_AD_VIDEO_CREDIT_COST['wan2.6'][durationKey as keyof typeof PRODUCT_AD_VIDEO_CREDIT_COST['wan2.6']]
      }
      // seedance (default)
      const durationKey = duration <= 5 ? 4 : duration <= 10 ? 8 : 12
      return PRODUCT_AD_VIDEO_CREDIT_COST.seedance[durationKey as keyof typeof PRODUCT_AD_VIDEO_CREDIT_COST.seedance]
    }
    const creditCostPerVideo = getVideoCreditCost()
    const totalCreditCost = creditCostPerVideo * count

    // íŠ¸ëœì­ì…˜ìœ¼ë¡œ í¬ë ˆë”§ í™•ì¸ ë° ì°¨ê° (ì›ìì  ì²˜ë¦¬)
    try {
      await prisma.$transaction(async (tx) => {
        const profile = await tx.profiles.findUnique({
          where: { id: user.id },
          select: { credits: true },
        })

        if (!profile || (profile.credits ?? 0) < totalCreditCost) {
          throw new Error('INSUFFICIENT_CREDITS')
        }

        await tx.profiles.update({
          where: { id: user.id },
          data: { credits: { decrement: totalCreditCost } },
        })
      }, { timeout: 10000 })
    } catch (error) {
      if (error instanceof Error && error.message === 'INSUFFICIENT_CREDITS') {
        const profile = await prisma.profiles.findUnique({
          where: { id: user.id },
          select: { credits: true },
        })
        return NextResponse.json(
          { error: 'Insufficient credits', required: totalCreditCost, available: profile?.credits ?? 0 },
          { status: 402 }
        )
      }
      throw error
    }

    // ê° ì˜ìƒì— ëŒ€í•´ í”„ë¡¬í”„íŠ¸ ìƒì„± ë° ìš”ì²­
    const requests: { requestId: string; prompt: string }[] = []

    try {
      for (let i = 0; i < count; i++) {
        // ëª¨ë¸ë³„ ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±
        const videoPrompt = multiShot
          ? await generateMultiShotPrompt(productName, scenarioElements, duration, videoModel, i)
          : await generateVideoPrompt(productName, scenarioElements, duration, videoModel, i)

        let result: { request_id: string }

        // ëª¨ë¸ì— ë”°ë¼ ë‹¤ë¥¸ API í˜¸ì¶œ
        switch (videoModel) {
          case 'wan2.6':
            result = await submitWan26ToQueue(
              startFrameUrl,
              videoPrompt,
              {
                duration: mapDurationForWan26(duration),
                resolution: '720p' as Wan26Resolution,
                multiShots: multiShot,  // ë©€í‹°ìƒ· í”„ë¡¬í”„íŠ¸ + API ë©€í‹°ìƒ· ì˜µì…˜ í•¨ê»˜ ì‚¬ìš©
              }
            )
            break

          case 'seedance':
          default:
            result = await submitSeedanceToQueue(
              startFrameUrl,
              null, // ë í”„ë ˆì„ ì—†ìŒ
              videoPrompt,
              {
                aspectRatio: mapAspectRatioForSeedance(aspectRatio),
                resolution: '720p',
                duration: mapDurationForSeedance(duration),
                fixedLens: false,
                generateAudio: false,
              }
            )
            break
        }

        requests.push({
          requestId: `kie:${result.request_id}`,
          prompt: videoPrompt,
        })
      }
    } catch (requestError) {
      // ì˜ìƒ ìƒì„± ìš”ì²­ ì‹¤íŒ¨ ì‹œ í¬ë ˆë”§ í™˜ë¶ˆ
      console.error('ì˜ìƒ ìƒì„± ìš”ì²­ ì‹¤íŒ¨, í¬ë ˆë”§ í™˜ë¶ˆ:', requestError)
      await prisma.profiles.update({
        where: { id: user.id },
        data: { credits: { increment: totalCreditCost } },
      })
      throw requestError
    }

    // Draftê°€ ìˆìœ¼ë©´ ìƒíƒœ ì—…ë°ì´íŠ¸ (ì²« ë²ˆì§¸ ìš”ì²­ ID ì €ì¥)
    if (draftId && requests.length > 0) {
      await prisma.video_ads.update({
        where: { id: draftId },
        data: {
          video_request_id: requests[0].requestId,
          status: 'GENERATING_VIDEO',
          updated_at: new Date(),
        },
      })
    }

    return NextResponse.json({
      requests,
      // í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ë‹¨ì¼ requestIdë„ ë°˜í™˜
      requestId: requests[0]?.requestId,
      prompt: requests[0]?.prompt,
      creditUsed: totalCreditCost,
    })
  } catch (error) {
    console.error('ì˜ìƒ ìƒì„± ì˜¤ë¥˜:', error)
    return NextResponse.json(
      { error: 'Failed to generate video' },
      { status: 500 }
    )
  }
}

async function generateVideoPrompt(
  productName: string,
  elements: ScenarioElements,
  duration: number,
  videoModel: VideoModel,
  variationIndex: number = 0
): Promise<string> {
  // ëª¨ë¸ë³„ ìµœì í™”ëœ íŒíŠ¸
  const modelSpecificGuidelines = getModelGuidelines(videoModel, false)

  const variationHints = [
    'Focus on elegant, slow motion and subtle product highlights.',
    'Emphasize dynamic lighting transitions and atmospheric depth.',
    'Create an artistic, cinematic feel with creative composition angles.',
  ]

  const prompt = `You are an expert advertising video prompt engineer.
Create an optimized video generation prompt for a product advertisement.

OUTPUT LANGUAGE: English (prompt must be in English for AI video generation)

=== TARGET MODEL ===
${videoModel === 'wan2.6' ? 'Wan 2.6 (Alibaba) - High resolution 1080p, excels at cinematic quality and detailed textures' : 'Seedance 1.5 Pro (ByteDance) - Smooth motion, natural movements, elegant transitions'}

=== PRODUCT INFORMATION ===
Product: [Refer to the product shown in the start frame image]

âš ï¸ WARNING: Do NOT include the product name "${productName}" directly in the generated prompt.
The product name may contain misleading words (e.g., "Camera Lens Cleaner" would generate actual cameras).
Instead, use generic terms like "the product", "the bottle", "the item" based on the start frame image.

=== SCENARIO ELEMENTS ===
Background/Location: ${elements.background}
Mood/Tone: ${elements.mood}
Composition/Angle: ${elements.cameraAngle}
Product Placement: ${elements.productPlacement}
Lighting Style: ${elements.lighting}
Color Tone: ${elements.colorTone}

=== VIDEO REQUIREMENTS ===
Duration: approximately ${duration} seconds
Starting Frame: Will be provided (the video should continue naturally from this frame)
Variation Style: ${variationHints[variationIndex % variationHints.length]}

=== MODEL-SPECIFIC GUIDELINES ===
${modelSpecificGuidelines}

=== GENERAL GUIDELINES ===
1. Describe smooth, natural motion for the product
2. Include motion and movement that enhances the product appeal
3. Maintain the established mood throughout
4. Keep the prompt concise but descriptive (50-80 words)
5. Avoid sudden changes or jarring transitions
6. The video should feel premium and polished

=== ğŸ¥ CAMERA STABILIZATION (ë§¤ìš° ì¤‘ìš”!) ===
- Use "steady", "stable", "gimbal-stabilized" keywords for smooth motion
- Include "no camera shake", "professional dolly motion" for stability
- AVOID "handheld", "shaky", "dynamic camera" - these cause unstable footage
- All motion should feel like professional broadcast/commercial quality

=== CRITICAL: NO VISIBLE EQUIPMENT ===
- NO cameras, tripods, lighting rigs, softboxes, ring lights, reflectors, or any studio equipment visible
- Describe lighting as EFFECT only (e.g., "soft highlights", "dramatic shadows"), NOT as visible equipment
- The video should look like a FINAL ADVERTISEMENT, not a behind-the-scenes production

âš ï¸ FORBIDDEN WORDS (ì´ ë‹¨ì–´ë“¤ì„ í”„ë¡¬í”„íŠ¸ì— í¬í•¨í•˜ë©´ ì´¬ì˜ ì¥ë¹„ê°€ ì˜ìƒì— ë“±ì¥í•¨!):
NEVER include: "camera", "tripod", "photographer", "filming", "behind the scenes", "DSLR", "mirrorless"

Create a single, optimized video prompt.`

  const config: GenerateContentConfig = {
    thinkingConfig: {
      thinkingLevel: ThinkingLevel.MEDIUM,
    },
    responseMimeType: 'application/json',
    responseSchema: {
      type: Type.OBJECT,
      required: ['prompt'],
      properties: {
        prompt: {
          type: Type.STRING,
          description: 'ì˜ìƒ ìƒì„± í”„ë¡¬í”„íŠ¸ (ì˜ì–´)',
        },
      },
    },
  }

  const response = await genAI.models.generateContent({
    model: MODEL_NAME,
    contents: [{ role: 'user', parts: [{ text: prompt }] }],
    config,
  })

  const responseText = response.text || ''
  const result = JSON.parse(responseText) as { prompt: string }

  return result.prompt
}

/**
 * ëª¨ë¸ë³„ ìµœì í™” ê°€ì´ë“œë¼ì¸ ë°˜í™˜
 */
function getModelGuidelines(videoModel: VideoModel, isMultiShot: boolean): string {
  if (videoModel === 'wan2.6') {
    return isMultiShot
      ? `For Wan 2.6 Multi-Shot:
- Leverage 1080p high resolution for detailed close-ups
- Use dramatic motion between shots (dolly-in, crane shots, tracking)
- Include clear visual transitions between shots
- Focus on cinematic storytelling with emotional build-up
- Each shot should have distinct framing and composition`
      : `For Wan 2.6:
- Leverage 1080p resolution for crisp, detailed product shots
- Include cinematic motion (slow dolly, elegant pans)
- Focus on high-quality textures and reflections
- Use dramatic lighting transitions
- Emphasize visual depth and atmosphere`
  }

  // Seedance (default)
  return isMultiShot
    ? `For Seedance Multi-Shot:
- Focus on smooth, fluid transitions between shots
- Use gentle motion that flows naturally
- Maintain consistent lighting across shots
- Keep product as the visual anchor throughout
- Emphasize elegant, premium feel in each shot`
    : `For Seedance:
- Prioritize smooth, natural motion throughout
- Use slow, elegant motion (gentle dolly, subtle pan)
- Focus on fluid product motion (smooth rotation, gentle floating)
- Maintain soft lighting transitions
- Create a polished, refined aesthetic`
}

/**
 * ë©€í‹°ìƒ· í”„ë¡¬í”„íŠ¸ ìƒì„± (ì—¬ëŸ¬ ìƒ·ìœ¼ë¡œ êµ¬ì„±ëœ ì‹œë„¤ë§ˆí‹± ì˜ìƒ)
 */
async function generateMultiShotPrompt(
  productName: string,
  elements: ScenarioElements,
  duration: number,
  videoModel: VideoModel,
  variationIndex: number = 0
): Promise<string> {
  // durationì— ë”°ë¥¸ ìƒ· ìˆ˜ ê²°ì •
  const shotCount = duration <= 5 ? 2 : duration <= 10 ? 3 : 4
  const modelSpecificGuidelines = getModelGuidelines(videoModel, true)

  const variationStyles = [
    'cinematic product reveal sequence',
    'dynamic showcase with multiple angles',
    'storytelling approach with emotional impact',
  ]

  const prompt = `You are an expert advertising video prompt engineer specializing in multi-shot sequences.
Create a multi-shot video prompt for a premium product advertisement.

OUTPUT LANGUAGE: English (prompt must be in English for AI video generation)

=== TARGET MODEL ===
${videoModel === 'wan2.6' ? 'Wan 2.6 (Alibaba) - Native multi-shot support, 1080p resolution, cinematic quality' : 'Seedance 1.5 Pro (ByteDance) - Smooth transitions, natural motion, 720p'}

=== PRODUCT INFORMATION ===
Product: [Refer to the product shown in the start frame image]

âš ï¸ WARNING: Do NOT include the product name "${productName}" directly in the generated prompt.
The product name may contain misleading words (e.g., "Camera Lens Cleaner" would generate actual cameras).
Instead, use generic terms like "the product", "the bottle", "the item" based on the start frame image.

=== SCENARIO ELEMENTS ===
Background/Location: ${elements.background}
Mood/Tone: ${elements.mood}
Composition/Angle: ${elements.cameraAngle}
Product Placement: ${elements.productPlacement}
Lighting Style: ${elements.lighting}
Color Tone: ${elements.colorTone}

=== VIDEO REQUIREMENTS ===
Total Duration: approximately ${duration} seconds
Number of Shots: ${shotCount}
Style: ${variationStyles[variationIndex % variationStyles.length]}
Starting Frame: Will be provided

=== MULTI-SHOT FORMAT ===
Use this exact format:
"Shot 1: [description]. Shot 2: [description]. Shot 3: [description]."

=== REFERENCE EXAMPLES ===
Example 1 (Product Focus): "Shot 1: Close-up on the product, soft professional lighting highlights its sleek surface. Shot 2: View slowly pulls back revealing the premium packaging. Shot 3: Product rotates elegantly, catching light reflections as view dollies around."

Example 2 (Cinematic): "Shot 1: Wide establishing shot of minimalist setting with product centered. Shot 2: Dynamic dolly-in to hero shot, dramatic lighting builds. Shot 3: Extreme close-up on product details, lens flare accents the premium finish."

=== MODEL-SPECIFIC GUIDELINES ===
${modelSpecificGuidelines}

=== GENERAL GUIDELINES ===
1. Each shot should be distinct but flow naturally into the next
2. Start with establishing shot, build to hero shot of the product
3. Include specific motion (dolly-in, pan, close-up, etc.)
4. End with a memorable final shot showcasing the product
5. Keep each shot description concise (15-25 words)
6. Total prompt should be 60-120 words

=== ğŸ¥ CAMERA STABILIZATION (ë§¤ìš° ì¤‘ìš”!) ===
- Use "steady", "stable", "gimbal-stabilized" keywords for smooth motion
- Include "no camera shake", "professional dolly motion" for stability
- AVOID "handheld", "shaky", "dynamic camera" - these cause unstable footage
- All motion should feel like professional broadcast/commercial quality

=== CRITICAL: NO VISIBLE EQUIPMENT ===
- NO cameras, tripods, lighting rigs, softboxes, ring lights, reflectors, or any studio equipment visible
- Describe lighting as EFFECT only (e.g., "soft highlights", "dramatic shadows"), NOT as visible equipment
- The video should look like a FINAL ADVERTISEMENT, not a behind-the-scenes production

âš ï¸ FORBIDDEN WORDS (ì´ ë‹¨ì–´ë“¤ì„ í”„ë¡¬í”„íŠ¸ì— í¬í•¨í•˜ë©´ ì´¬ì˜ ì¥ë¹„ê°€ ì˜ìƒì— ë“±ì¥í•¨!):
NEVER include: "camera", "tripod", "photographer", "filming", "behind the scenes", "DSLR", "mirrorless"

Create a multi-shot prompt that tells a compelling visual story about the product.`

  const config: GenerateContentConfig = {
    thinkingConfig: {
      thinkingLevel: ThinkingLevel.MEDIUM,
    },
    responseMimeType: 'application/json',
    responseSchema: {
      type: Type.OBJECT,
      required: ['prompt'],
      properties: {
        prompt: {
          type: Type.STRING,
          description: 'ë©€í‹°ìƒ· ì˜ìƒ ìƒì„± í”„ë¡¬í”„íŠ¸ (ì˜ì–´, Shot 1: ... Shot 2: ... í˜•ì‹)',
        },
      },
    },
  }

  const response = await genAI.models.generateContent({
    model: MODEL_NAME,
    contents: [{ role: 'user', parts: [{ text: prompt }] }],
    config,
  })

  const responseText = response.text || ''
  const result = JSON.parse(responseText) as { prompt: string }

  return result.prompt
}
