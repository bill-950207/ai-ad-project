/**
 * ì”¬ë³„ ì˜ìƒ í”„ë¡¬í”„íŠ¸ ìƒì„± API (Vidu Q2 / Kling O1ìš©)
 *
 * POST: ì‹œë‚˜ë¦¬ì˜¤ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê° ì”¬ì˜ ê°œë³„ ì˜ìƒ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
 * - ê° ì”¬ì€ ê°œë³„ ì˜ìƒìœ¼ë¡œ ìƒì„±ëœ í›„ ë‚˜ì¤‘ì— í•©ì³ì§
 * - ëª¨ë“  ì”¬ì˜ í†¤ì•¤ë§¤ë„ˆ/ìƒ‰ê°/ì¡°ëª…ì´ ì¼ê´€ë˜ì–´ì•¼ ìì—°ìŠ¤ëŸ¬ìš´ í•©ì„± ê°€ëŠ¥
 * - ì‚¬ëŒ/ì–¼êµ´ ì œì™¸, ì œí’ˆ ì¤‘ì‹¬ ê´‘ê³ 
 */

import { NextRequest, NextResponse } from 'next/server'
import { createClient } from '@/lib/supabase/server'
import { GoogleGenAI, GenerateContentConfig, ThinkingLevel, Type } from '@google/genai'

// Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
const genAI = new GoogleGenAI({
  apiKey: process.env.GOOGLE_AI_API_KEY!,
})

const MODEL_NAME = 'gemini-3-flash-preview'

interface ScenarioElements {
  background: string
  mood: string
  cameraAngle: string
  productPlacement: string
  lighting: string
  colorTone: string
}

interface GenerateMultiSceneRequest {
  productName: string
  productDescription?: string | null
  productImageUrl?: string | null
  sellingPoints?: string[] | null  // ì œí’ˆ ì…€ë§ í¬ì¸íŠ¸
  scenarioElements: ScenarioElements
  scenarioDescription?: string
  sceneCount?: number  // ìƒì„±í•  ì”¬ ìˆ˜ (ê¸°ë³¸ 3)
  totalDuration?: number  // ì „ì²´ ì˜ìƒ ê¸¸ì´ (ì´ˆ)
}

interface SceneOutput {
  index: number
  scenePrompt: string       // ì´ ì”¬ì˜ ê°œë³„ ì˜ìƒ í”„ë¡¬í”„íŠ¸ - ëª¨ì…˜ í¬í•¨, ì‚¬ëŒ ì œì™¸ (ì˜ì–´)
  duration: number          // ì”¬ ì˜ìƒ ê¸¸ì´ (3-8ì´ˆ)
  movementAmplitude: 'auto' | 'small' | 'medium' | 'large'  // ì¹´ë©”ë¼/ëª¨ì…˜ ê°•ë„
}

/**
 * URLì—ì„œ ì´ë¯¸ì§€ë¥¼ ê°€ì ¸ì™€ base64ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
 */
async function fetchImageAsBase64(url: string): Promise<{ base64: string; mimeType: string } | null> {
  try {
    const response = await fetch(url)
    if (!response.ok) return null

    const contentType = response.headers.get('content-type') || 'image/jpeg'
    const buffer = await response.arrayBuffer()
    const base64 = Buffer.from(buffer).toString('base64')

    return { base64, mimeType: contentType }
  } catch (error) {
    console.error('ì´ë¯¸ì§€ ë¡œë“œ ì˜¤ë¥˜:', error)
    return null
  }
}

export async function POST(request: NextRequest) {
  try {
    const supabase = await createClient()
    const { data: { user }, error: authError } = await supabase.auth.getUser()

    if (authError || !user) {
      return NextResponse.json(
        { error: 'Unauthorized' },
        { status: 401 }
      )
    }

    const body: GenerateMultiSceneRequest = await request.json()
    const {
      productName,
      productDescription,
      productImageUrl,
      sellingPoints,
      scenarioElements,
      scenarioDescription,
      sceneCount = 3,
      totalDuration = 15,
    } = body

    if (!productName || !scenarioElements) {
      return NextResponse.json(
        { error: 'Missing required fields' },
        { status: 400 }
      )
    }

    // ê° ì”¬ì˜ í‰ê·  ê¸¸ì´ ê³„ì‚° (ìµœì†Œ 3ì´ˆ, ìµœëŒ€ 10ì´ˆ)
    const avgDuration = Math.min(10, Math.max(3, Math.floor(totalDuration / (sceneCount - 1))))

    // ì œí’ˆ ì´ë¯¸ì§€ base64 ë³€í™˜ (ìˆì„ ê²½ìš°)
    let productImageData: { base64: string; mimeType: string } | null = null
    if (productImageUrl) {
      productImageData = await fetchImageAsBase64(productImageUrl)
    }

    const prompt = buildMultiScenePrompt(
      productName,
      productDescription,
      sellingPoints,
      scenarioElements,
      scenarioDescription,
      sceneCount,
      avgDuration
    )

    const config: GenerateContentConfig = {
      thinkingConfig: {
        thinkingLevel: ThinkingLevel.MEDIUM,
      },
      responseMimeType: 'application/json',
      responseSchema: {
        type: Type.OBJECT,
        required: ['scenes', 'visualStyle'],
        properties: {
          scenes: {
            type: Type.ARRAY,
            description: 'ìƒì„±ëœ ì”¬ë³„ ê°œë³„ ì˜ìƒ í”„ë¡¬í”„íŠ¸ ë°°ì—´',
            items: {
              type: Type.OBJECT,
              required: ['index', 'scenePrompt', 'duration', 'movementAmplitude'],
              properties: {
                index: {
                  type: Type.NUMBER,
                  description: 'ì”¬ ì¸ë±ìŠ¤ (0ë¶€í„° ì‹œì‘)',
                },
                scenePrompt: {
                  type: Type.STRING,
                  description: 'ì´ ì”¬ì˜ ê°œë³„ ì˜ìƒ í”„ë¡¬í”„íŠ¸ - ëª¨ì…˜ í¬í•¨, ì‚¬ëŒ ì œì™¸, 40-60ë‹¨ì–´ (ì˜ì–´)',
                },
                duration: {
                  type: Type.NUMBER,
                  description: 'ì”¬ ì˜ìƒ ê¸¸ì´ (ì´ˆ, 3-8)',
                },
                movementAmplitude: {
                  type: Type.STRING,
                  description: 'ì¹´ë©”ë¼/ëª¨ì…˜ ê°•ë„: small(ì •ì , ë¯¸ì„¸í•œ ì›€ì§ì„), medium(ì ë‹¹í•œ ì¹´ë©”ë¼ ì´ë™), large(ì—­ë™ì  ì›€ì§ì„), auto(ìë™)',
                  enum: ['auto', 'small', 'medium', 'large'],
                },
              },
            },
          },
          visualStyle: {
            type: Type.STRING,
            description: 'ëª¨ë“  ì”¬ì— ì ìš©ëœ ê³µí†µ ì‹œê°ì  ìŠ¤íƒ€ì¼ (ì¡°ëª…, ìƒ‰ê°, ë¶„ìœ„ê¸°) ìš”ì•½ - ì˜ì–´',
          },
          narrativeFlow: {
            type: Type.STRING,
            description: 'ì „ì²´ ì˜ìƒì˜ ë‚´ëŸ¬í‹°ë¸Œ íë¦„ ì„¤ëª… (í•œêµ­ì–´)',
          },
        },
      },
    }

    // ë©€í‹°ëª¨ë‹¬ ì½˜í…ì¸  êµ¬ì„± (ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸)
    const parts: Array<{ text: string } | { inlineData: { mimeType: string; data: string } }> = []

    // ì œí’ˆ ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ ë¨¼ì € ì¶”ê°€
    if (productImageData) {
      parts.push({
        inlineData: {
          mimeType: productImageData.mimeType,
          data: productImageData.base64,
        },
      })
    }

    // í”„ë¡¬í”„íŠ¸ ì¶”ê°€
    parts.push({ text: prompt })

    const response = await genAI.models.generateContent({
      model: MODEL_NAME,
      contents: [{ role: 'user', parts }],
      config,
    })

    const responseText = response.text || ''
    const result = JSON.parse(responseText) as {
      scenes: SceneOutput[]
      visualStyle?: string
      narrativeFlow?: string
    }

    return NextResponse.json({
      scenes: result.scenes,
      visualStyle: result.visualStyle,
      narrativeFlow: result.narrativeFlow,
    })
  } catch (error) {
    console.error('ë©€í‹°ì”¬ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± ì˜¤ë¥˜:', error)
    return NextResponse.json(
      { error: 'Failed to generate multi-scene scenario' },
      { status: 500 }
    )
  }
}

function buildMultiScenePrompt(
  productName: string,
  productDescription: string | null | undefined,
  sellingPoints: string[] | null | undefined,
  elements: ScenarioElements,
  scenarioDescription: string | undefined,
  sceneCount: number,
  avgDuration: number
): string {
  // ì…€ë§ í¬ì¸íŠ¸ í¬ë§·íŒ…
  const sellingPointsText = sellingPoints && sellingPoints.length > 0
    ? sellingPoints.map((p, i) => `  ${i + 1}. ${p}`).join('\n')
    : 'Not provided'

  return `You are an expert advertising video director creating a PREMIUM AD CAMPAIGN with multiple creative scenes.

ğŸ¬ GOAL: Create ${sceneCount} DISTINCTLY DIFFERENT scenes that feel like a cohesive professional advertisement.
Each scene should tell a different part of the product story while maintaining the same premium mood.

=== CRITICAL RULES ===
âŒ ABSOLUTELY NO PEOPLE:
- NO humans, faces, hands, body parts, silhouettes
- ONLY the product, objects, environment, and natural elements

âœ… OUTPUT LANGUAGE:
- scenePrompt: English only (for AI video generation)
- visualStyle: English (shared style description)
- narrativeFlow: Korean (for user)

â­ MUST REFERENCE THE ATTACHED IMAGE:
- Each scenePrompt MUST start with "The product shown in the attached image" or "The exact product from the reference image"
- This ensures the AI image generator uses the EXACT product appearance from the attached image
- Describe how THIS SPECIFIC PRODUCT (from the image) is positioned and lit in each scene

=== PRODUCT INFORMATION (âš ï¸ CRITICAL - READ CAREFULLY) ===
Product Name: ${productName}
Product Description: ${productDescription || 'Not provided'}
Product Selling Points (í•µì‹¬ íŠ¹ì§•/ì¥ì ):
${sellingPointsText}
Product Image: [ATTACHED - This is the PRODUCT to feature]

ğŸ’¡ USE SELLING POINTS: Design scenes that visually communicate these selling points.
For example, if a selling point is "waterproof", show water droplets around the product.

âš ï¸ PRODUCT IDENTIFICATION:
- The attached image shows the PRODUCT: "${productName}"
- This is a COMMERCIAL PRODUCT for advertisement, NOT a living being
- Even if the product looks like a person (figurine, doll, statue, mannequin, action figure, character merchandise), it is a PRODUCT ITEM to be showcased
- Treat the product as an OBJECT/ITEM to be displayed elegantly in commercial scenes
- Examples of products that may look human-like but are PRODUCTS:
  * Figurines, action figures, collectibles â†’ Product items to display
  * Dolls, plush toys â†’ Product items to showcase
  * Statues, sculptures â†’ Art products to feature
  * Mannequins with clothing â†’ Fashion products to advertise

=== SCENARIO ELEMENTS ===
Background/Location: ${elements.background}
Mood/Tone: ${elements.mood}
Camera Angle: ${elements.cameraAngle}
Product Placement: ${elements.productPlacement}
Lighting Style: ${elements.lighting}
Color Tone: ${elements.colorTone}
${scenarioDescription ? `Scenario Description: ${scenarioDescription}` : ''}

=== â­ CREATIVE VARIETY (ë§¤ìš° ì¤‘ìš”!) ===
Think like a premium ad campaign director. Each scene should be VISUALLY DISTINCT:

1. **DIFFERENT COMPOSITIONS** - Each scene needs unique visual storytelling:
   - Scene with product as hero (center focus, dramatic)
   - Scene with product in context (lifestyle setting, environment)
   - Scene with dynamic elements (motion, particles, splashes)
   - Scene with detail/texture focus (macro, close-up details)
   - Scene with atmospheric mood (lighting effects, shadows)

2. **DIFFERENT VISUAL ELEMENTS** - Pick ONLY 1-2 per scene (not multiple):
   - Floating particles drifting slowly upward
   - Soft mist or steam rising gently
   - Fabric or petals falling slowly
   - Subtle light beams or rim lighting
   - Gentle reflections on surface
   âš ï¸ LIMIT: Maximum 2 effects per scene for clean AI video generation

3. **DIFFERENT CAMERA PERSPECTIVES** - Not just angle changes:
   - Wide establishing shot â†’ intimate close-up
   - Macro detail shot â†’ environmental context
   - Dynamic movement â†’ static elegance
   - Top-down flat lay â†’ dramatic low angle

=== âš ï¸ VIDU Q2 VIDEO AI OPTIMIZATION (ë§¤ìš° ì¤‘ìš”!) ===
These prompts will be used by Vidu Q2 AI video generator. Follow these rules STRICTLY:

1. **NO TEXT RENDERING** - Never mention product text, labels, or brand names to "pop" or be visible
   - AI video CANNOT maintain text - it will distort and look bad
   - âŒ WRONG: "making the 'Brand Name' text pop"
   - âœ… CORRECT: Just describe the product visually without text expectations

2. **SIMPLE SURFACE DESCRIPTIONS** - No contradictions
   - âŒ WRONG: "polished, reflective frosted glass" (contradiction)
   - âœ… CORRECT: "smooth dark reflective surface" OR "matte frosted surface" (pick one)

3. **SPECIFIC CAMERA MOVEMENTS** - Always include "slowly" and direction
   - âŒ WRONG: "Camera pulls back" (vague)
   - âœ… CORRECT: "Camera slowly pulls back to reveal the full product"
   - âœ… CORRECT: "Slow cinematic dolly out revealing full product"

4. **LIMIT VISUAL EFFECTS** - Maximum 2 effects per scene
   - âŒ WRONG: "lens flares + micro-particles + backlighting + silhouette" (too many)
   - âœ… CORRECT: "rim lighting creates silhouette, tiny particles float slowly upward"

5. **USE SIMPLE, CLEAR LANGUAGE** - Short sentences, concrete verbs
   - âŒ WRONG: "ethereal light rays streaming through and illuminating"
   - âœ… CORRECT: "soft light beams shine through"

=== ğŸ¨ MOOD CONSISTENCY (í†¤ì•¤ë§¤ë„ˆ í†µì¼) ===
While scenes are VISUALLY DIFFERENT, they should share the SAME FEELING:

1. **SAME COLOR GRADING** - Consistent color temperature and mood
   - Use the same color tone keywords in all scenes
   - Example: "warm golden tones" or "cool blue atmosphere"

2. **SAME QUALITY LEVEL** - Premium, cinematic feel throughout
   - End every prompt with: "premium commercial, cinematic lighting, photorealistic, 4K"

3. **SAME BRAND FEELING** - Cohesive luxury/premium aesthetic
   - All scenes should feel like they belong to the same brand campaign

=== SCENE PROMPT STRUCTURE (50-80 words) ===
Each scenePrompt MUST:
1. START by identifying the product: "The [product type: ${productName}] shown in the attached image"
2. Clearly state it's a PRODUCT/ITEM being showcased (not a living being)
3. Be UNIQUE and CREATIVE
4. Follow this structure:

[Product identification with name]. [Scene concept]. [How the PRODUCT ITEM is positioned/displayed]. [Specific visual elements]. [Camera movement]. [Atmospheric details]. [Color/mood keywords]. [Quality keywords].

Example format: "The ${productName} product shown in the attached image is elegantly displayed on..."

=== ğŸ¥ PROMPT ENDING TEMPLATE ===
EVERY scenePrompt MUST end with this consistent quality suffix:
"${elements.colorTone} tones, cinematic lighting, photorealistic, 4K"

This ensures visual consistency across all scenes.

=== CAMERA MOVEMENTS (âš ï¸ ALWAYS include "slowly") ===
âœ… CORRECT camera movement phrases:
- "Camera slowly pushes in toward the product"
- "Camera slowly pulls back to reveal the full product"
- "Camera slowly arcs around the product"
- "Camera slowly glides past revealing the scene"
- "Camera slowly tilts up/down"
- "Slow cinematic dolly out"
- "Slow zoom into product details"

âŒ WRONG (too vague):
- "Camera pulls back" (missing speed)
- "Camera moves around" (no direction)

=== ğŸšï¸ MOVEMENT AMPLITUDE (Vidu Q2 Parameter) ===
For each scene, choose the appropriate movementAmplitude value:

- **"small"** - For static, elegant shots with minimal movement
  * Close-up detail shots, product hero shots
  * Subtle particle floating, gentle light shifts
  * Best for: luxurious, sophisticated feel

- **"medium"** - For moderate camera movement (RECOMMENDED for most scenes)
  * Slow push-in, gentle arc around product
  * Balanced motion that feels cinematic
  * Best for: professional commercial look

- **"large"** - For dynamic, energetic shots
  * Dramatic reveals, sweeping camera moves
  * More particles, faster environmental motion
  * Best for: attention-grabbing opening/closing shots

- **"auto"** - Let AI decide (use sparingly)
  * Only when unsure about the right intensity

ğŸ’¡ TIP: Vary movementAmplitude across scenes for visual rhythm:
- Scene 1 (opening): "medium" or "large" for attention
- Middle scenes: "small" or "medium" for elegance
- Final scene: "medium" for memorable close

=== DURATION ===
- Each scene: ${avgDuration} seconds (range: 3-8)

=== ğŸ¬ SCENE PROGRESSION (ì”¬ ê°„ ì—°ê²°ì„± - ë§¤ìš° ì¤‘ìš”!) ===
Design scenes as a CONNECTED VISUAL JOURNEY, not random separate shots:

**OPENING (Scene 1):**
- Establish the product and setting
- Create curiosity - partial reveal, mysterious angle, or dramatic entrance
- Camera: medium/large movement for attention
- End state should naturally lead to Scene 2

**DEVELOPMENT (Middle scenes):**
- Each scene reveals MORE about the product
- Progress logically: far â†’ close, hidden â†’ revealed, mystery â†’ clarity
- Maintain visual connections:
  * Same environment/location feel
  * Consistent lighting direction
  * Logical camera flow (if Scene 1 ends wide, Scene 2 can start wide)
- Camera: small/medium movement for elegance

**CLIMAX (Final scene):**
- Full product reveal or hero moment
- Culmination of the visual journey
- Most premium, polished presentation
- Camera: medium movement for memorable close

**TRANSITION LOGIC:**
Create scenes that feel like they belong together in one story:
- If Scene 1 shows product in shadow â†’ Scene 2 shows light hitting product â†’ Scene 3 shows fully illuminated product
- If Scene 1 is wide environmental â†’ Scene 2 is medium product context â†’ Scene 3 is intimate close-up
- Each scene should answer a question raised by the previous scene

Generate ${sceneCount} CONNECTED scene prompts for "${productName}".

âš ï¸ CRITICAL REQUIREMENTS:
1. Each prompt MUST start with "The ${productName} product from the attached image"
2. Use words like "product", "item", "displayed", "showcased" to clarify it's a PRODUCT
3. Even if the product resembles a human (figurine, doll, statue), describe it as a PRODUCT ITEM
4. Each scene must be DISTINCTLY DIFFERENT while sharing the same premium mood
5. NO REAL PEOPLE - only the product and environment elements
6. SCENE PROGRESSION: Scenes must feel CONNECTED as a visual journey (opening â†’ development â†’ climax)
7. Each prompt MUST end with: "${elements.colorTone} tones, cinematic lighting, photorealistic, 4K"

âš ï¸ VIDU Q2 VIDEO AI RULES (MANDATORY):
8. NO text/label rendering expectations - never mention product text or brand names
9. Simple surface descriptions - no contradictions (e.g., NOT "reflective frosted")
10. ALL camera movements MUST include "slowly" (e.g., "Camera slowly pulls back")
11. Maximum 2 visual effects per scene - keep it clean and achievable`
}
